{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kenya Constitution AI Agent – Business Understanding\n",
    "\n",
    "## Project Context\n",
    "The Kenyan Constitution of 2010 is a comprehensive legal document that governs the country's laws and citizens' rights. However, it is long, complex, and written in legal language that can be difficult for the general population, especially youths, to understand. \n",
    "\n",
    "Accessing relevant information quickly can be challenging, making it difficult for citizens to exercise their rights or comply with legal obligations.\n",
    "\n",
    "## Business Problem\n",
    "*Problem Statement:*  \n",
    "Citizens, especially young people, need an accessible way to understand and query the Kenyan Constitution in everyday language. Traditional legal consultation is expensive, and reading the full document is time-consuming.\n",
    "\n",
    "*Objective:*  \n",
    "Develop an AI agent that uses Natural Language Processing (NLP) to understand user queries and provide relevant answers from the Constitution. The agent should:\n",
    "\n",
    "- Accept questions in *English and Kiswahili*.\n",
    "- Return accurate, understandable answers.\n",
    "- Quote the specific article/section from the Constitution for credibility.\n",
    "\n",
    "*Stakeholders:*  \n",
    "- Kenyan youths (primary users)\n",
    "- NGOs and civic education organizations\n",
    "- Government institutions promoting civic engagement\n",
    "\n",
    "## Expected Impact\n",
    "- *Empowerment:* Citizens can better understand their rights and duties.\n",
    "- *Accessibility:* Reduces reliance on legal experts for basic constitutional questions.\n",
    "- *Scalability:* The system can be deployed online and integrated via API for wider use.\n",
    "\n",
    "## Key Considerations\n",
    "- Language support (English + Kiswahili)\n",
    "- Handling legal jargon\n",
    "- Accurate referencing of articles/chapters\n",
    "- Efficient query handling for fast responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Data Understanding\n",
    "\n",
    "## Overview of the Data\n",
    "For this project, our data sources are:\n",
    "\n",
    "1. *English version of the Kenyan Constitution (2010)*  \n",
    "   - Source: [The Constitution of Kenya 2010 PDF](Data/The_Constitution_of_Kenya_2010.pdf)  \n",
    "   - Contains all chapters, articles, and legal provisions in English.  \n",
    "   - Needs text extraction and cleaning to convert it into a structured format for NLP.\n",
    "\n",
    "2. *Kiswahili version of the Kenyan Constitution*  \n",
    "   - Source: [Kielelezo_Pantanifu_cha_Katiba_ya_Kenya.pdf](Data/Kielelezo_Pantanifu_cha_Katiba_ya_Kenya.pdf)  \n",
    "   - Same content as the English version, translated into Kiswahili.  \n",
    "   - Requires extraction, cleaning, and alignment with the English dataset.\n",
    "\n",
    "*Purpose of Using Both Languages:*  \n",
    "- Enable the AI agent to respond to user queries in *English* or *Kiswahili*.  \n",
    "- Improve accessibility and inclusivity for all Kenyan citizens.  \n",
    "\n",
    "## Data Structure\n",
    "After preprocessing, the expected data structure is:\n",
    "\n",
    "| Article/Section | Text (English) | Text (Kiswahili) |\n",
    "|-----------------|----------------|-----------------|\n",
    "| Article 1       | Text content   | Swahili content |\n",
    "| Article 2       | Text content   | Swahili content |\n",
    "| ...             | ...            | ...             |\n",
    "\n",
    "*Notes:*  \n",
    "- Each row corresponds to an *article* or *clause*.  \n",
    "- This will allow the NLP model to retrieve relevant sections when users ask questions.  \n",
    "\n",
    "## Data Quality Considerations\n",
    "- PDFs contain headers, footers, and formatting that need cleaning.  \n",
    "- Ensure *text alignment* between English and Kiswahili versions.  \n",
    "- Maintain *article/chapter references* to allow citations in responses.  \n",
    "\n",
    "## Next Steps\n",
    "1. Extract text from PDFs into a structured format (JSON/CSV).  \n",
    "2. Clean text by removing:\n",
    "   - Page numbers\n",
    "   - Footnotes\n",
    "   - Unnecessary whitespace and formatting characters  \n",
    "3. Verify consistency between English and Kiswahili versions.  \n",
    "4. Prepare a dataset ready for:\n",
    "   - Embeddings creation\n",
    "   - NLP query retrieval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\tinah\\anaconda3\\moringa\\lib\\site-packages (0.11.7)\n",
      "Requirement already satisfied: pdfminer.six==20250506 in c:\\users\\tinah\\anaconda3\\moringa\\lib\\site-packages (from pdfplumber) (20250506)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\tinah\\anaconda3\\moringa\\lib\\site-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\tinah\\anaconda3\\moringa\\lib\\site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\tinah\\anaconda3\\moringa\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\tinah\\anaconda3\\moringa\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\tinah\\anaconda3\\moringa\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tinah\\anaconda3\\moringa\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.21)\n",
      "pdfplumber installed successfully!\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber\n",
    "import pdfplumber\n",
    "print(\"pdfplumber installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Preview:\n",
      " LAWS OF KENYA\n",
      "THE CONSTITUTION OF KENYA, 2010\n",
      "Published by the National Council for Law Reporting\n",
      "with the Authority of the Attorney-General\n",
      "www.kenyalaw.org\n",
      "Constitution of Kenya, 2010\n",
      "THE CONSTITUTION OF KENYA, 2010\n",
      "ARRANGEMENT OF ARTICLES\n",
      "PREAMBLE\n",
      "CHAPTER ONE—SOVEREIGNTY OF THE PEOPLE AND\n",
      "SUPREMACY OF THIS CONSTITUTION\n",
      "1—Sovereignty of the people.\n",
      "2—Supremacy of this Constitution.\n",
      "3—Defence of this Constitution.\n",
      "CHAPTER TWO—THE REPUBLIC\n",
      "4—Declaration of the Republic.\n",
      "5—Territory of Kenya.\n",
      "6—Devolution and access to services.\n",
      "7—National, official and other languages.\n",
      "8—State and religion.\n",
      "9—National symbols and national days.\n",
      "10—National values and principles of governance.\n",
      "11—Culture.\n",
      "CHAPTER THREE—CITIZENSHIP\n",
      "12—Entitlements of citizens.\n",
      "13—Retention and acquisition of citizenship.\n",
      "14—Citizenship by birth.\n",
      "15—Citizenship by registration.\n",
      "16—Dual citizenship.\n",
      "17—Revocation of citizenship.\n",
      "18—Legislation on citizenship.\n",
      "CHAPTER FOUR—THE BILL OF RIGHTS\n",
      "PART 1—GENERAL PROVISIONS RELATI\n",
      "\n",
      "Kiswahili Preview:\n",
      " �������������������\n",
      "�������������������\n",
      "���������������������������������������������������\n",
      "���������������������������������������������������\n",
      "��������������������������������������������\n",
      "�������������������������\n",
      "KIELELEZO PATANIFU CHA KATIBA YA KENYA\n",
      "2 JUMAPILI, NOVEMBA 22, 2009\n",
      "Imechapishwa mnamo Novemba 17, 2009 na Kamati ya Wataalam Kuhusu Marekebisho ya Katiba Kulingana na\n",
      "Sehemu 32(1)(a)(i) ya Sheria ya Marekebisho ya Katiba ya Kenya, 2008.\n",
      "40. Vijana\n",
      "UTANGULIZI\n",
      "41. Watoto\n",
      "42. Familia\n",
      "43. Walemavu\n",
      "SURA YA KWANZA\n",
      "44. Makundi Tengwa\n",
      "45. Hadhi ya kibinadamu\n",
      "46. Uhuru na usalama wa mtu\n",
      "UTAWALA WA WATU NA MAMLAKA YA KATIBA\n",
      "47. Utumwa na kazi ya kulazimishwa\n",
      "1. Utawala wa watu\n",
      "48. Usiri\n",
      "2. Mamlaka ya Katiba\n",
      "49. Uhuru wa dhamiri, dini, imani na maoni\n",
      "3. Kulinda Katiba\n",
      "50. Uhuru wa kujieleza\n",
      "51. Uhuru wa vyombo vya habari\n",
      "SURA YA PILI 52. Uwezo wa kuafikia habari\n",
      "53. Uhuru wa kutangamana\n",
      "54. Mikutano, maandamano, migomo na malalamishi\n",
      "JAMHURI 55. Haki za kisiasa\n",
      "4. Ikirari ya Jamhuri 5\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pdfplumber  # For PDF text extraction\n",
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "english_pdf_path = \"../Data/The_Constitution_of_Kenya_2010.pdf\"\n",
    "kiswahili_pdf_path = \"../Data/Kielelezo_Pantanifu_cha_Katiba_ya_Kenya.pdf\"\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_pdf_text(pdf_path):\n",
    "    all_text = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                all_text.append(text)\n",
    "    return \"\\n\".join(all_text)\n",
    "\n",
    "# Extract English and Kiswahili texts\n",
    "english_text = extract_pdf_text(english_pdf_path)\n",
    "kiswahili_text = extract_pdf_text(kiswahili_pdf_path)\n",
    "\n",
    "# Optional: Preview first 1000 characters\n",
    "print(\"English Preview:\\n\", english_text[:1000])\n",
    "print(\"\\nKiswahili Preview:\\n\", kiswahili_text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m kiswahili_articles \u001b[38;5;241m=\u001b[39m split_articles(kiswahili_text, keyword\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKifungu\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Kiswahili keyword\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame for structured dataset\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArticle/Section\u001b[39m\u001b[38;5;124m\"\u001b[39m: [art[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m art \u001b[38;5;129;01min\u001b[39;00m english_articles],\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText_English\u001b[39m\u001b[38;5;124m\"\u001b[39m: [art[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m art \u001b[38;5;129;01min\u001b[39;00m english_articles],\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText_Kiswahili\u001b[39m\u001b[38;5;124m\"\u001b[39m: [art[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m art \u001b[38;5;129;01min\u001b[39;00m kiswahili_articles]  \u001b[38;5;66;03m# Align carefully\u001b[39;00m\n\u001b[0;32m     29\u001b[0m })\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Preview structured dataset\u001b[39;00m\n\u001b[0;32m     32\u001b[0m data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Moringa\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\anaconda3\\Moringa\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Moringa\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Moringa\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Function to split text into articles/chapters (simple approach, refine later)\n",
    "def split_articles(text, keyword=\"Article\"):\n",
    "    \"\"\"\n",
    "    Splits the Constitution text into articles based on the keyword.\n",
    "    Returns a list of tuples: (Article Number/Title, Text)\n",
    "    \"\"\"\n",
    "    import re\n",
    "    # Split text on keyword \"Article\" followed by number/word\n",
    "    pattern = rf\"({keyword} \\d+.*?)\\n\"\n",
    "    splits = re.split(pattern, text)\n",
    "    \n",
    "    articles = []\n",
    "    # Combine article titles with their text\n",
    "    for i in range(1, len(splits), 2):\n",
    "        title = splits[i].strip()\n",
    "        body = splits[i+1].strip() if i+1 < len(splits) else \"\"\n",
    "        articles.append((title, body))\n",
    "    return articles\n",
    "\n",
    "# Split English and Kiswahili texts into articles\n",
    "english_articles = split_articles(english_text, keyword=\"Article\")\n",
    "kiswahili_articles = split_articles(kiswahili_text, keyword=\"Kifungu\")  # Kiswahili keyword\n",
    "\n",
    "# Convert to DataFrame for structured dataset\n",
    "data = pd.DataFrame({\n",
    "    \"Article/Section\": [art[0] for art in english_articles],\n",
    "    \"Text_English\": [art[1] for art in english_articles],\n",
    "    \"Text_Kiswahili\": [art[1] for art in kiswahili_articles]  # Align carefully\n",
    "})\n",
    "\n",
    "# Preview structured dataset\n",
    "data.head(5)\n",
    "\n",
    "# Save to CSV for further use in NLP pipeline\n",
    "data.to_csv(\"Data/kenya_constitution_structured.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
